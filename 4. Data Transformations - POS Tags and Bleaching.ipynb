{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Transformations - POS Tags and Bleaching.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script takes the raw data csv file and transforms the post to their respective POS tags as well s bleached format\n",
    "\n",
    "The Consonant vowel bleaching method is used because it will keep the length of the words as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/danielcauchi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csv_filename = 'data/PostsList.csv'\n",
    "\n",
    "pos_filename = 'data/POS.csv'\n",
    "bleaching_filename = 'data/Bleached.csv'\n",
    "\n",
    "dataframe_columns = ['PostID', 'Post', 'Gender', 'TrainTest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame(columns=dataframe_columns)\n",
    "df_pos.to_csv(pos_filename, index=False)\n",
    "\n",
    "df_bleach = pd.DataFrame(columns=dataframe_columns)\n",
    "df_bleach.to_csv(bleaching_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to return POS tag sentence given a post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(post):\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(post))\n",
    "    return ' '.join([t[1] for t in tags])\n",
    "\n",
    "bleach_dic = defaultdict(int)\n",
    "bleach_dic['a'] = bleach_dic['A'] = 'V'\n",
    "bleach_dic['b'] = bleach_dic['B'] = 'C'\n",
    "bleach_dic['c'] = bleach_dic['C'] = 'C'\n",
    "bleach_dic['d'] = bleach_dic['D'] = 'C'\n",
    "bleach_dic['e'] = bleach_dic['E'] = 'V'\n",
    "bleach_dic['f'] = bleach_dic['F'] = 'C'\n",
    "bleach_dic['g'] = bleach_dic['G'] = 'C'\n",
    "bleach_dic['h'] = bleach_dic['H'] = 'C'\n",
    "bleach_dic['i'] = bleach_dic['I'] = 'V'\n",
    "bleach_dic['j'] = bleach_dic['J'] = 'C'\n",
    "bleach_dic['k'] = bleach_dic['K'] = 'C'\n",
    "bleach_dic['l'] = bleach_dic['L'] = 'C'\n",
    "bleach_dic['m'] = bleach_dic['M'] = 'C'\n",
    "bleach_dic['n'] = bleach_dic['N'] = 'C'\n",
    "bleach_dic['o'] = bleach_dic['O'] = 'V'\n",
    "bleach_dic['p'] = bleach_dic['P'] = 'C'\n",
    "bleach_dic['q'] = bleach_dic['Q'] = 'C'\n",
    "bleach_dic['r'] = bleach_dic['R'] = 'C'\n",
    "bleach_dic['s'] = bleach_dic['S'] = 'C'\n",
    "bleach_dic['t'] = bleach_dic['T'] = 'C'\n",
    "bleach_dic['u'] = bleach_dic['U'] = 'V'\n",
    "bleach_dic['v'] = bleach_dic['V'] = 'C'\n",
    "bleach_dic['w'] = bleach_dic['W'] = 'C'\n",
    "bleach_dic['x'] = bleach_dic['X'] = 'C'\n",
    "bleach_dic['y'] = bleach_dic['Y'] = 'C'\n",
    "bleach_dic['z'] = bleach_dic['Z'] = 'C'\n",
    "\n",
    "def bleach_character(c):\n",
    "    if bleach_dic[c] == 0:\n",
    "        return c\n",
    "    return bleach_dic[c]\n",
    "\n",
    "def bleach(post):\n",
    "    result=len(post)*[None]\n",
    "    for i,c in enumerate(post):\n",
    "        result[i] = bleach_character(c)\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open, traverse and convert the posts in the raw data CSV file to POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "\n",
    "number_of_posts = sum(1 for line in open(raw_csv_filename)) -1\n",
    "\n",
    "number_of_chunks = math.ceil(number_of_posts / chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12928/69190"
     ]
    }
   ],
   "source": [
    "with open(pos_filename, 'a') as posF, open(bleaching_filename, 'a') as bleachF:\n",
    "    for i,chunk in enumerate(pd.read_csv(raw_csv_filename, chunksize=chunksize)):\n",
    "        chunk = chunk.dropna()\n",
    "        \n",
    "        clear_output()\n",
    "        print('{0}/{1}'.format((i+1), number_of_chunks), end = '', flush=True)\n",
    "\n",
    "        # Extract data from each file\n",
    "        df_pos = df_pos.iloc[0:0]\n",
    "        df_bleach = df_bleach.iloc[0:0]\n",
    "        for row in chunk.iterrows():\n",
    "            entry_pos = {\n",
    "                'PostID': row[1][0],\n",
    "                'Post': get_pos(row[1][3]),\n",
    "                'Gender': row[1][2], # This field will help in the next step\n",
    "                'TrainTest': row[1][4] # This field will help in the next step\n",
    "            }\n",
    "            entry_bleach = {\n",
    "                'PostID': row[1][0],\n",
    "                'Post': bleach(row[1][3]),\n",
    "                'Gender': row[1][2], # This field will help in the next step\n",
    "                'TrainTest': row[1][4] # This field will help in the next step\n",
    "            }\n",
    "            \n",
    "            df_pos = df_pos.append(entry_pos, ignore_index=True)\n",
    "            df_bleach = df_bleach.append(entry_bleach, ignore_index=True)\n",
    "            \n",
    "        df_pos.to_csv(posF, header=False, index=False)\n",
    "        df_bleach.to_csv(bleachF, header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
