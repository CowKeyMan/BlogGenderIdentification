{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Extraction 1 - Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script reads all the blog files and puts them in one CSV file containing the following columns:\n",
    "   * PostID - As an index of sorts\n",
    "   * UserID - To keep track for when there is the need of splitting between trainign and testing\n",
    "   * Gender - Target value\n",
    "   * Post - The raw text of the post, trimmed of spaces from the front or after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/blogs/'\n",
    "\n",
    "csv_filename = 'data/PostsList.csv'\n",
    "\n",
    "train_test_df = pd.read_csv('data/AuthorTrainTest.csv', index_col=['UserID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise dataframe and target CSV filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['PostID', 'UserID', 'Gender', 'Post', 'TrainTest'])\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract and clean the posts obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_posts(filename):\n",
    "    global PostID, df\n",
    "    df=df.iloc[0:0]\n",
    "    with open(data_path + filename, \"rb\", encoding=None) as f:\n",
    "        contents = f.read().decode('utf8', 'ignore')\n",
    "        \n",
    "    soup = BeautifulSoup(contents, 'html')\n",
    "    \n",
    "    meta = filename.split('.')\n",
    "    UserID = int(meta[0])\n",
    "    Gender = meta[1]\n",
    "    \n",
    "    TrainTest = train_test_df.loc[UserID]['TrainTest']\n",
    "    \n",
    "    for post in soup.findAll('post'):\n",
    "        Post = post.text.strip()\n",
    "        # New lines are removed and will not be considered.\n",
    "        # Instead they are replaced by fullstops since this will work well for our processing\n",
    "        # Some users were shown to not end their sentences with\n",
    "        # fullstops before a newline, so we do it for them\n",
    "        Post = Post.replace('\\r\\n','.').replace('\\n','.')\n",
    "        \n",
    "        entry = {\n",
    "            'PostID': PostID,\n",
    "            'UserID': UserID,\n",
    "            'Gender': Gender,\n",
    "            'Post': Post,\n",
    "            'TrainTest': TrainTest\n",
    "        }\n",
    "    \n",
    "        df = df.append(entry, ignore_index=True)\n",
    "\n",
    "        PostID +=1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - 19320 files\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all the xml files and get number of files (to see how much is left)\n",
    "number_of_files = len(os.listdir(data_path))\n",
    "    \n",
    "PostID = 0\n",
    "# open CSV file in append mode\n",
    "with open(csv_filename, 'a') as f:\n",
    "    for i, filename in enumerate(os.listdir(data_path)):\n",
    "        clear_output()\n",
    "        print('{0}/{1}'.format((i+1), number_of_files), end = '', flush=True)\n",
    "        \n",
    "        # Extract data from each file\n",
    "        df = extract_posts(filename)\n",
    "        df.to_csv(f, header=False, index=False)\n",
    "\n",
    "clear_output()\n",
    "print('DONE - {0} files'.format(number_of_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
